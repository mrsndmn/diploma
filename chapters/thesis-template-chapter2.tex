\chapter{Разработка моделей и алгоритмов}

\begin{annotation}
	В данной главе описывается модифицированная модель
	когнитивных карт с использованием
	рекуррентных нейросетей и сетей прямого распространения.
	Производится выбор метрик оценки качества работы системы.
\end{annotation}

\section{LSTM NFCM -~ Long Short-Serm Memory Neural Fuzzy Cognotive Map}

Можно усовершенствовать модель TTR LSTM, рассмотренную в предыдущем разделе,
если вместо сетей прямого распространения использовать рекуррентные сети,
например, LSTM \cite{LSTM_paper}. Такая сеть позволит более естественно
сохранять информацию об истории концептов в своем скрытом состоянии,
а для того, чтобы учитывать значения концептов на предыдущих итерациях
в сетях прямого распространения, каждый предыдущий шаг должен быть
описан как отдельная "фича", как отдельный параметр модели.

Сравнение LSTM NFCM с полносвязными сетями:
У LSTM NFCM меньше параметров по сравнению с сетью прямого распространения,
которая бы учитывала больше количество предыдущих значений во временном ряде.
LSTM NFCM дольше обучается, но имеет значительно лучшую способность к предсказанию
на длинных временных рядах.
Модель будет дольше обучаться, потому что нельзя распараллелить
процесс обучения LSTM сетей, так как в сети учитывается, что внутренее состояние меняется последовательно.
LSTM NFCM имеет лучшую интерпретируемость, так как содержит
экспертную информацию о взаимосвязи концептов.
Но для построения LSTM NFCM требуется эксперт, а как следствие,
ручная работа.

Сравнение LSTM NFCM с TTR NFCM:
LSTM NFCM дольше обучается, но на сложных данных
может иметь более точные прогнозы.

Сравнение LSTM NFCM с LSTM:
LSTM сеть, которая бы соответствовала LSTM NFCM, будет иметь
больше параметров в случае, если граф LSTM NFCM не слишком
много связей. LSTM NFCM лучше интерпретируема.
Скорость обучения, при условии оптимизаций в LSTM NFCM, с
помощью которых обучение LSTM моделей в каждой вершине бы проходило
параллельно, будет примерно одинаковой.
Предсказательная способность должна быть лучше у LSTM NFCM.
Потому что такая модель более проста и структурирована.
LSTM модель может оказаться излишне усложненной, так как в ней будет
большое количество параметров.
Но для построения LSTM NFCM требуется эксперт, а как следствие,
ручная работа.
Для построения LSTM NFCM требуется эксперт.

Кроме того, так как карта представляет из себя ансамбль
более маленьких моделей, в случае ошибки в исходных данных
в одной части модели, можно переобучать не всю карту целиком,
а только ту часть в которой была ошибка. Так как процесс обучения
может занимать долгое время, эта оптимизация может существенно ускорить процесс.
Такой же прием можно применить и для случая, когда надо дообучить карту на
новом наборе данных: можно дообучать карту частями.

\section{Построение LSTM NFCM}

Для того, чтобы создать модель, нужно определить параметры системы, концепты.
Каждый концепт будет соответствовать вершине графа карты.
После того, как концепты определены, нужно описать взаимодействие между концептами.
Одним из вариантов может быть полносвязный граф, когда каждый концепт имеет
влияние на каждый другой концепт. Теоретически, при увеличении количества
связей в модели, количество возможных зависимостей, которые она может описать
увеличивается. Однако, усложняется и сама модель так, что ее становится сложно обучить.
Слишком сложные модели легко переобучаются на тестовых данных.
Задача эксперта как раз заключается в том, что он должен
описать только необходимые и достаточные взаимосвязи.

Так же, как и большое количество взаимосвязей,
недостаточное количество связей или неверные связи, могут ухудшить
качество модели. Модель может оказаться недостаточно мощной, чтобы описать
исследуемый процесс. Поэтому важно найти именно существенные связи.

После того, как карта построена, необходимо "заморозить карту".
Это означает, что новые связи в карте больше появляться не будут.
Это необходимо для того, чтобы рассчитать параметры моделей, которые
лежат в каждой вершине графа карты: размерность данных на входе,
размерность внутреннего состояния, размерность данных на выходе модели.
Перед заморозкой для каждого концепта должна быть определена модель,
которая будет использована при моделировании данного концепта: ARIMAX или LSTM.
При выборе стоит учитывать особенности и возможности каждой модели.
ARIMAX более интерпретируема и легка, но LSTM может обнаружить
скрытые связи более сложного характера, в том числе долгосрочные.

Для того, чтобы добавить новый концепт после заморозки карты,
потребуется переобучить карту. Как описано в предыдущем абзаце,
нет необходимости переобучать всю карту целиком. Нужно переобучить только
концепт, к которому добавилась новая связь.

После "заморозки", должны быть инициализированы модели в каждой вершине
карты. Эксперт имеет возможность задать создать любую модель заданной размерности
для каждого концепта отдельно. Выбор модели должен быть основан
на характере данных. Можно использовать как авторегрессионные модели,
так и нелинейные, в том числе и нейросетевые. Также можно использовать различные комбинации
этих подходов. Например, "boosting multi-step autoregressive" \ref{taieb2014boosting}.
В данной работе будет использоваться LSTM и ARIMAX.

\section{Предобработка данных}

Существуют методы, с помощью которых можно избавиться от сезонности
в данных. Но тут, кажется, что нам это не нужно, потому что есть LSTM'ка

\section{Алгоритм обучения LSTM NFCM}

% todo нужен рисунок
Каждый концепт имеет исторические данные, которые используются
для обучения модели концепта.

Процесс обучения можно разбить на несколько шагов:

\begin{itemize}
	\item Подготовка данных.
	\item Тренировка сети.
	\item Валидация обученной сети.
\end{itemize}

Подготовка данных. На этом этапе происходит разбиение
исторических данных на части для обучения и для валидации.
Это необходимо, чтобы не допустить переобучения сети:
когда на выборке для обучения показатели качества сети
отличные, но на валидационной выборке плохие.
В подготовку данных также нужно включить преобразование данных
в последовательности необходимой размерности. На вход
LSTM сеть принимает матрицу размерности $ seq_len \times batch \times input_size $.
$ seq_len $ -~ длинна последовательности, непрерывный кусок данных.
$ batch $ -~ размер пакета на каждой итерации, для которого будет вычисляться градиент.
$ input_size $ -~ количество связей, которые входят в обучаемый концепт.

Тренировка сети. На данном шаге происходит оптимизиция весов
сети каждого концепта. В качестве оптимизатора
можно взять RMSSE. % todo на самом деле, я этого не сделал, там сейчас просто MSE
В секции "Выбор метрик для оценки качества работы алгоритмов"
приводится обоснование данного выбора.
В качестве оптимизатора будет использован ADAM \ref{adam2014}.
% todo обоснования нет. Можно потестить, мб есть чтополучше

% \section{Оценка сложности алгоритма обучения LSTM NFCM}

% возможные оптимизации
% можно параллельно обучать каждую маленькую модель
% можно уменьшать скрытый слой отдельно для каждой модели
% и использовать вручную сгенерированные фичи

\section{Алгоритм вычисления LSTM NFCM}

% todo нужен рисунок

Алгоритм вычисления LSTM-NFCM не сильно отличается от
алгоритма вычисления классической нечеткой когнитивной карты.

Предсказание одной итерации в LSTM-NFCM ничем не будет отличаться
от предсказаний тех моделей, которые заложены в вершины графа.
Можно провести несколько итераций вычисления карты, с учетом вычисленных
данных. На следующем шаге модель будет обрабатывать данные,
которые сгенерировала на предыдущем шаге. Таким образом можно получить
более долгосрочное предсказание.

Кроме того, в такой модели должны проявиться влияния обратных связей, которые могут
быть заложены в архитектуре карты, если карта содержит циклы.
Таким образом, в LSTM-NFCM есть 2 уровня обратных связей:
на уровне модели концепта (LSTM) и на уровне структуры карты,
если карта содержит обратные связи.
Обратные связи на уровне структуры карты интересны тем, что
через них можно было бы выразить циклически меняющееся состояние системы.

Другой способ получить более долгосрочные предсказания -~ обучить LSTM
предсказывать на большее количество итераций вперед. Такой подход
требует больше памяти.



\section{Возможные проблемы алгоритма}

Для обучения  нейросети требуется, чтобы
данные для обучения были репрезентативными. То есть
описывали все возможные значения, которые может принимать система.
Если в предсказании появляются данные, которых не было в обучающей выборке,
модель нужно переобучать. Можно предположить, что эту проблему можно решить,
если использовать версию LSTM без функции активации или, возможно, с другой
функцией активации, например, ReLU. ReLU просто вычислять. И в отличие от
сигмоиды, она не ограничена сверху. Также можно использовать другую модель.
При краткосрочном прогнозировании данный недостаток на является существенным.
Кроме того, такой проблемы можно избежать, если избавиться от тренда с
помощью интегрированной регрессионной модели так, чтобы на вход нейросети
поступал стационарный ряд.

Если внутреннее состояние будет иметь большую размерность,
модель будет потреблять много памяти. Возможно, модель можно
декомпозировать на меньшие задачи и обойтись несколькими концептами
с меньшей размерностью внутреннего состояния.
Но данный метод не относится к методам, в которых нужно просто
пользоваться моделью, как молотилкой. А нацелен на то, чтобы наоборот
получить больше понимания об изучаемом процессе.

При достаточно большом количестве временных рядов,
становится сложно экспертно определить взаимодействие между концептами.
Для задач с большим количеством рядов для исследования, без
модификаций, данный метод не будет эффективен. Так как потребует
большое количество вычислительных ресурсов.
Для таких задач можно использовать, например, градиентный бустинг \ref{friedman2002stochastic}.

\section{Возможные дальнейшие направления для исследований}

Предложенная модель довольно долго обучается и требует много ресурсов
для вычисления. Если найти способ более быстрого вычисления,
теоретически, даже при большом наборе временных рядов, которые нужно
исследовать, можно было бы перебрать различные комбинации взаимосвязей концептов.
Для такой задачи хорошо подошли бы адаптивные модели.

Исследовать возможность распространения градиента по нескольким вершинам
графа. Теоретически, это может улучшить качество модели, но потребует больше
памяти, вычислительных мощностей.

\section{Выбор метрик для оценки качества работы алгоритмов}

Кросс-валидация -~ это метод оценки модели на данных, не участвовавших
в обучении модели. Особенностью кросс-валидации для задачи прогнозирования
временных рядов заключается в том, перемешивать данные нельзя,
так как порядок данных во временном ряде -~ это его неотъемлемая составляющая.
Модель будет обучена на 90\% данных и ошибка предсказаний будет измерена
для оставшихся 10\% выборки.

В качестве критерия качества результата работы системы для предсказаний
для одного временного ряда, можно взять среднеквадратическую
масштабированную ошибку (RMSSE) \ref{hyndman2006another}.
Она вычисляется она по формуле \ref{img:rmsse}

% todo кажется, я это и не использовал
\def\figurename{Формула}
\begin{figure}
	\centering
	$ RMSSE = \sqrt{ \frac{ \frac{1}{h} \sum_{t=n+1}^{n+h}(Y_t - \hat{Y_t})^2  }{ \frac{1}{n-1} \sum_{t=2}^{n} (Y_t - Y_{t-1})^2 } } $,

	\caption{Root Mean Squared Scaled Error.
	(
		$ h $ ~- горизонт предсказаний,
		$ n $ ~- количество измерений обучающей выборки,
		$ Y_t $ ~- истинное значение временного ряда в момент времени $ t $,
		$ \hat{Y_t} $ ~- предсказанное значение временного ряда в момент времени $ t $
	)}
	\label{img:rmsse}
\end{figure}
\def\figurename{Рис.}

Данная метрика обладает рядом преимуществ:

\begin{itemize}
	\item Ошибка не зависит от масштаба и может быть эффективно использована для предсказаний временных рядов разных масштабов.
	\item Функция может быть вычислена безопасно. Деление на ноль может произойти только если временной ряд состоял из одного повторяющегося числа.
	\item Одинаково штрафуются и положительные, и отрицательные отклонения, метрика симметрична.
\end{itemize}

Для того, чтобы оценить получить ошибку по предсказанию для всех временных рядов,
можно использовать взвешенную среднеквадратическую масштабированную ошибку.
Она вычисляется по формуле \ref{wrmsse}

\def\figurename{Формула}
\begin{figure}
	\centering
	$ WRMSSE = \sum_{i=1}^{k} w_i * RMSSE_i $,
	\caption{
		Weighted Root Mean Squared Scaled Error.
		(
			$ k $ ~- количество временных рядов,
			$ w_i $ ~- вес ошибки временного ряда $ i $
		)
	}
	\label{img:wrmsse}
\end{figure}
\def\figurename{Рис.}

Для того, чтобы оценить, какую именно информацию о системе наша
модель не может объяснить, можно построить коррелограмму и использовать
статистические критерии для того, чтобы определить, являются ли остатки
белым шумом. В данной работе будет использоваться критерий KPSS \ref{kpss}

% todo не могу это объяснить!
% https://youtu.be/u433nrxdf5k?t=1554
\def\figurename{Формула}
\begin{figure}
	\centering
	$ KPSS(y) = \frac{1}{T^{2} \lambda^2 } \sum^{T}_{i=1}{ \( \sum^{i}_{t=1}{y_t} \)^{2} } $,
	\caption{
		Расчет критерия KPSS.
	}
	\label{img:kpss}
\end{figure}
\def\figurename{Рис.}

Для определения оптимальных гиперпараметров ARIMAX модели будет использоваться Акаике.
Это критерий используется для сравнения одинаковых моделей с разными гиперпараметрами.
Чем меньше значение этого критерия, тем оптимальнее набор гиперпараметров.
Для случая, когда модели обучены на выборках одинаковой длинны, этот критерий можно вычислить по формуле \ref{akaike_creiterion}.
Чем больше значения гиперпараметров ($ p $, $ q $, $ P $, $ Q $) для ARIMAX модели, тем более лучшие
результаты будут получены на тестовой выборке. Поэтому эти гиперпараметры нельзя
выбирать из принципа максимального правдоподобия.

% +1 в `k = ...` -- это, наверное, константа
\def\figurename{Формула}
\begin{figure}
	\centering
	$ AIC = 2k - 2 ln(L) $,
	\caption{
		Критерий Акаике для моделей, обученных на выборках одинаковой длинны.
		$ k = p + q + P + Q + 1 $ -~ количество параметров
		$ L $ -~ количество параметров
	}
	\label{img:akaike_creiterion}
\end{figure}
\def\figurename{Рис.}


\section{Выводы}

В данной главе была рассмотрена модель когнитивных карт.
Была разработана модель когнитивных карт
с использованием нейросетей (рекуррентных и прямого распространения).
Были выбраны методы оценки качества работы разрабатываемой системы
и методы оптимизации параметров разработанной модели.